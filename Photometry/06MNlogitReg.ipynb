{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install scikit-learn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.preprocessing import StandardScaler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.head of       ID    Date  Trial#  Lever  NextLever  WSLS  LeverZmax  LeverZmin  \\\n",
       "20    16  230123      21      3          2     1   2.401602  -1.003824   \n",
       "21    16  230123      22      3          2     1   2.926855  -1.217437   \n",
       "22    16  230123      23      3          2     1   1.696856  -1.406294   \n",
       "23    16  230123      24      3          2     1   1.724995  -1.203465   \n",
       "24    16  230123      25      3          2     1   0.747431  -1.450247   \n",
       "...   ..     ...     ...    ...        ...   ...        ...        ...   \n",
       "1672  32  230407      51      3          1     3   3.332265  -1.602789   \n",
       "1673  32  230407      52      1          0     0   4.506867  -2.054242   \n",
       "1674  32  230407      55      1          2     0   0.637471  -3.201188   \n",
       "1675  32  230407      56      2          0     2   2.911747  -0.353442   \n",
       "1676  32  230407      59      1          0     0   1.568098  -1.403199   \n",
       "\n",
       "        LeverAUC    HLZmax    HLZmin       HLAUC  \n",
       "20     80.581480  2.714354 -3.457057   16.780465  \n",
       "21     60.036972  1.345199 -1.114219    6.998765  \n",
       "22     16.301229  2.525270 -0.910631   73.202751  \n",
       "23    -16.434931  2.817282 -1.062264  108.825146  \n",
       "24    -57.158955  0.230749 -2.294819  -65.399567  \n",
       "...          ...       ...       ...         ...  \n",
       "1672  115.062938  2.267571 -2.405807  -11.777912  \n",
       "1673  145.104620  6.938257  1.800629  426.061993  \n",
       "1674 -152.723927  4.361066 -1.459229   88.204134  \n",
       "1675  142.243917  2.542664  0.129606  105.039027  \n",
       "1676   -1.866457  4.031175 -1.432087  117.981146  \n",
       "\n",
       "[1040 rows x 12 columns]>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "behav = pd.read_csv('../data/300behavior.csv')\n",
    "\n",
    "# Assuming behav is your DataFrame and it's already imported\n",
    "# Replace all occurrences of 3 with 2 in the 'NextLever' column\n",
    "behav['NextLever'] = behav['NextLever'].replace(3, 2)\n",
    "B23behav = behav[(behav['Trial#'] > 20) & ~(behav['Trial#'].isin([40, 60]))]\n",
    "\n",
    "B23behav.head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        19\n",
      "           1       0.00      0.00      0.00        30\n",
      "           2       0.84      1.00      0.91       263\n",
      "\n",
      "    accuracy                           0.84       312\n",
      "   macro avg       0.28      0.33      0.30       312\n",
      "weighted avg       0.71      0.84      0.77       312\n",
      "\n",
      "Confusion Matrix:\n",
      " [[  0   0  19]\n",
      " [  0   0  30]\n",
      " [  0   0 263]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\wonnp\\Documents\\GitHub\\ML-For-Beginners\\.virtualenv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\wonnp\\Documents\\GitHub\\ML-For-Beginners\\.virtualenv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\wonnp\\Documents\\GitHub\\ML-For-Beginners\\.virtualenv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# Example dataset\n",
    "# Replace this with your actual dataset\n",
    "X = B23behav[['LeverZmax','LeverZmin','LeverAUC','HLZmax','HLZmin','HLAUC']]  # Predictor variables\n",
    "y = B23behav['NextLever']  # Target variable with three categories\n",
    "\n",
    "# Splitting data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Standardizing the features (important for logistic regression models)\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Create a multinomial logistic regression model\n",
    "# 'multinomial' specifies that the target variable has more than two classes\n",
    "# 'lbfgs' is an optimization algorithm suitable for multinomial logistic regression\n",
    "model = LogisticRegression(multi_class='multinomial', solver='lbfgs')\n",
    "\n",
    "# Fit the model on the training data\n",
    "model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Predict on the testing data\n",
    "y_pred = model.predict(X_test_scaled)\n",
    "\n",
    "# Evaluating the model\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficients matrix:\n",
      " [[ 0.45619586 -0.07252622  0.05001933 -0.10097724  0.21127587 -0.08198394]\n",
      " [-0.59927257  0.20260698 -0.14344996  0.03653222  0.06428852  0.00120559]\n",
      " [ 0.14307671 -0.13008076  0.09343063  0.06444503 -0.2755644   0.08077835]]\n",
      "Class 0:\n",
      "  LeverZmax: 0.45619585834608994\n",
      "  LeverZmin: -0.0725262224663269\n",
      "  LeverAUC: 0.05001932879842498\n",
      "  HLZmax: -0.10097724386851054\n",
      "  HLZmin: 0.21127587473494006\n",
      "  HLAUC: -0.08198394107540016\n",
      "\n",
      "Class 1:\n",
      "  LeverZmax: -0.5992725694764093\n",
      "  LeverZmin: 0.20260698297031957\n",
      "  LeverAUC: -0.14344995541197678\n",
      "  HLZmax: 0.03653221760728464\n",
      "  HLZmin: 0.06428852091186907\n",
      "  HLAUC: 0.0012055916528571301\n",
      "\n",
      "Class 2:\n",
      "  LeverZmax: 0.14307671113031886\n",
      "  LeverZmin: -0.13008076050399295\n",
      "  LeverAUC: 0.09343062661355166\n",
      "  HLZmax: 0.06444502626122509\n",
      "  HLZmin: -0.27556439564680796\n",
      "  HLAUC: 0.08077834942254163\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Extracting the coefficients\n",
    "coefficients = model.coef_\n",
    "\n",
    "# Displaying the coefficients\n",
    "print(\"Coefficients matrix:\\n\", coefficients)\n",
    "\n",
    "feature_names = ['LeverZmax','LeverZmin','LeverAUC','HLZmax','HLZmin','HLAUC']  # Assuming X is a DataFrame\n",
    "\n",
    "for class_index in range(coefficients.shape[0]):\n",
    "    print(f\"Class {class_index}:\")\n",
    "    for feature_index in range(coefficients.shape[1]):\n",
    "        print(f\"  {feature_names[feature_index]}: {coefficients[class_index, feature_index]}\")\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.2.1 -> 23.3.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting statsmodels\n",
      "  Obtaining dependency information for statsmodels from https://files.pythonhosted.org/packages/52/fc/4c0e654ab177558a657eaba369e5a25fbf700f95f1d122f6c083525d58c4/statsmodels-0.14.1-cp312-cp312-win_amd64.whl.metadata\n",
      "  Downloading statsmodels-0.14.1-cp312-cp312-win_amd64.whl.metadata (9.8 kB)\n",
      "Requirement already satisfied: numpy<2,>=1.18 in c:\\users\\wonnp\\documents\\github\\ml-for-beginners\\.virtualenv\\lib\\site-packages (from statsmodels) (1.26.2)\n",
      "Requirement already satisfied: scipy!=1.9.2,>=1.4 in c:\\users\\wonnp\\documents\\github\\ml-for-beginners\\.virtualenv\\lib\\site-packages (from statsmodels) (1.11.4)\n",
      "Requirement already satisfied: pandas!=2.1.0,>=1.0 in c:\\users\\wonnp\\documents\\github\\ml-for-beginners\\.virtualenv\\lib\\site-packages (from statsmodels) (2.1.4)\n",
      "Collecting patsy>=0.5.4 (from statsmodels)\n",
      "  Obtaining dependency information for patsy>=0.5.4 from https://files.pythonhosted.org/packages/32/0e/0039df17094e8d9d26b69bd8e976e179b1f6cc772f9ffb597640d5016772/patsy-0.5.5-py2.py3-none-any.whl.metadata\n",
      "  Downloading patsy-0.5.5-py2.py3-none-any.whl.metadata (3.5 kB)\n",
      "Requirement already satisfied: packaging>=21.3 in c:\\users\\wonnp\\documents\\github\\ml-for-beginners\\.virtualenv\\lib\\site-packages (from statsmodels) (23.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\wonnp\\documents\\github\\ml-for-beginners\\.virtualenv\\lib\\site-packages (from pandas!=2.1.0,>=1.0->statsmodels) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\wonnp\\documents\\github\\ml-for-beginners\\.virtualenv\\lib\\site-packages (from pandas!=2.1.0,>=1.0->statsmodels) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\wonnp\\documents\\github\\ml-for-beginners\\.virtualenv\\lib\\site-packages (from pandas!=2.1.0,>=1.0->statsmodels) (2023.3)\n",
      "Requirement already satisfied: six in c:\\users\\wonnp\\documents\\github\\ml-for-beginners\\.virtualenv\\lib\\site-packages (from patsy>=0.5.4->statsmodels) (1.16.0)\n",
      "Downloading statsmodels-0.14.1-cp312-cp312-win_amd64.whl (9.8 MB)\n",
      "   ---------------------------------------- 0.0/9.8 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/9.8 MB 1.3 MB/s eta 0:00:08\n",
      "   ---------------------------------------- 0.1/9.8 MB 1.3 MB/s eta 0:00:08\n",
      "   - -------------------------------------- 0.3/9.8 MB 2.2 MB/s eta 0:00:05\n",
      "   - -------------------------------------- 0.4/9.8 MB 2.3 MB/s eta 0:00:05\n",
      "   -- ------------------------------------- 0.6/9.8 MB 2.7 MB/s eta 0:00:04\n",
      "   -- ------------------------------------- 0.6/9.8 MB 2.7 MB/s eta 0:00:04\n",
      "   --- ------------------------------------ 0.8/9.8 MB 2.8 MB/s eta 0:00:04\n",
      "   ---- ----------------------------------- 1.1/9.8 MB 3.0 MB/s eta 0:00:03\n",
      "   ---- ----------------------------------- 1.2/9.8 MB 3.2 MB/s eta 0:00:03\n",
      "   ----- ---------------------------------- 1.5/9.8 MB 3.3 MB/s eta 0:00:03\n",
      "   ------ --------------------------------- 1.5/9.8 MB 3.3 MB/s eta 0:00:03\n",
      "   ------- -------------------------------- 1.8/9.8 MB 3.4 MB/s eta 0:00:03\n",
      "   -------- ------------------------------- 2.0/9.8 MB 3.4 MB/s eta 0:00:03\n",
      "   -------- ------------------------------- 2.1/9.8 MB 3.4 MB/s eta 0:00:03\n",
      "   --------- ------------------------------ 2.2/9.8 MB 3.3 MB/s eta 0:00:03\n",
      "   --------- ------------------------------ 2.4/9.8 MB 3.3 MB/s eta 0:00:03\n",
      "   ---------- ----------------------------- 2.5/9.8 MB 3.3 MB/s eta 0:00:03\n",
      "   ----------- ---------------------------- 2.7/9.8 MB 3.4 MB/s eta 0:00:03\n",
      "   ----------- ---------------------------- 2.9/9.8 MB 3.4 MB/s eta 0:00:03\n",
      "   ------------ --------------------------- 3.1/9.8 MB 3.4 MB/s eta 0:00:02\n",
      "   ------------- -------------------------- 3.3/9.8 MB 3.4 MB/s eta 0:00:02\n",
      "   ------------- -------------------------- 3.4/9.8 MB 3.4 MB/s eta 0:00:02\n",
      "   -------------- ------------------------- 3.5/9.8 MB 3.4 MB/s eta 0:00:02\n",
      "   -------------- ------------------------- 3.7/9.8 MB 3.3 MB/s eta 0:00:02\n",
      "   --------------- ------------------------ 3.8/9.8 MB 3.4 MB/s eta 0:00:02\n",
      "   ---------------- ----------------------- 4.0/9.8 MB 3.4 MB/s eta 0:00:02\n",
      "   ----------------- ---------------------- 4.2/9.8 MB 3.4 MB/s eta 0:00:02\n",
      "   ----------------- ---------------------- 4.4/9.8 MB 3.4 MB/s eta 0:00:02\n",
      "   ------------------ --------------------- 4.5/9.8 MB 3.4 MB/s eta 0:00:02\n",
      "   ------------------- -------------------- 4.7/9.8 MB 3.4 MB/s eta 0:00:02\n",
      "   ------------------- -------------------- 4.9/9.8 MB 3.4 MB/s eta 0:00:02\n",
      "   -------------------- ------------------- 5.0/9.8 MB 3.5 MB/s eta 0:00:02\n",
      "   --------------------- ------------------ 5.2/9.8 MB 3.4 MB/s eta 0:00:02\n",
      "   --------------------- ------------------ 5.3/9.8 MB 3.4 MB/s eta 0:00:02\n",
      "   ---------------------- ----------------- 5.5/9.8 MB 3.4 MB/s eta 0:00:02\n",
      "   ----------------------- ---------------- 5.7/9.8 MB 3.4 MB/s eta 0:00:02\n",
      "   ----------------------- ---------------- 5.8/9.8 MB 3.4 MB/s eta 0:00:02\n",
      "   ------------------------ --------------- 6.0/9.8 MB 3.4 MB/s eta 0:00:02\n",
      "   ------------------------ --------------- 6.1/9.8 MB 3.5 MB/s eta 0:00:02\n",
      "   ------------------------- -------------- 6.3/9.8 MB 3.4 MB/s eta 0:00:02\n",
      "   -------------------------- ------------- 6.5/9.8 MB 3.4 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 6.6/9.8 MB 3.4 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 6.8/9.8 MB 3.5 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 7.0/9.8 MB 3.5 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 7.1/9.8 MB 3.5 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 7.3/9.8 MB 3.5 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 7.5/9.8 MB 3.5 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 7.7/9.8 MB 3.5 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 7.9/9.8 MB 3.5 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 8.0/9.8 MB 3.5 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 8.2/9.8 MB 3.5 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 8.4/9.8 MB 3.5 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 8.6/9.8 MB 3.5 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 8.7/9.8 MB 3.5 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 8.9/9.8 MB 3.5 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 9.1/9.8 MB 3.5 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 9.2/9.8 MB 3.5 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 9.4/9.8 MB 3.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------  9.6/9.8 MB 3.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------  9.7/9.8 MB 3.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 9.8/9.8 MB 3.5 MB/s eta 0:00:00\n",
      "Downloading patsy-0.5.5-py2.py3-none-any.whl (234 kB)\n",
      "   ---------------------------------------- 0.0/234.1 kB ? eta -:--:--\n",
      "   ------------------------ --------------- 143.4/234.1 kB 4.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 234.1/234.1 kB 3.6 MB/s eta 0:00:00\n",
      "Installing collected packages: patsy, statsmodels\n",
      "Successfully installed patsy-0.5.5 statsmodels-0.14.1\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.534831\n",
      "         Iterations 7\n",
      "                          MNLogit Regression Results                          \n",
      "==============================================================================\n",
      "Dep. Variable:              NextLever   No. Observations:                  728\n",
      "Model:                        MNLogit   Df Residuals:                      714\n",
      "Method:                           MLE   Df Model:                           12\n",
      "Date:                Mon, 01 Jan 2024   Pseudo R-squ.:                 0.05240\n",
      "Time:                        21:46:51   Log-Likelihood:                -389.36\n",
      "converged:                       True   LL-Null:                       -410.89\n",
      "Covariance Type:            nonrobust   LLR p-value:                 2.208e-05\n",
      "===============================================================================\n",
      "NextLever=1       coef    std err          z      P>|z|      [0.025      0.975]\n",
      "-------------------------------------------------------------------------------\n",
      "const           1.3347      0.637      2.095      0.036       0.086       2.583\n",
      "LeverZmax      -0.4040      0.174     -2.321      0.020      -0.745      -0.063\n",
      "LeverZmin       0.0847      0.149      0.569      0.569      -0.207       0.376\n",
      "LeverAUC       -0.0010      0.004     -0.283      0.777      -0.008       0.006\n",
      "HLZmax          0.0930      0.314      0.296      0.767      -0.523       0.709\n",
      "HLZmin         -0.1734      0.396     -0.438      0.662      -0.949       0.603\n",
      "HLAUC           0.0010      0.006      0.166      0.868      -0.011       0.013\n",
      "-------------------------------------------------------------------------------\n",
      "NextLever=2       coef    std err          z      P>|z|      [0.025      0.975]\n",
      "-------------------------------------------------------------------------------\n",
      "const           1.9606      0.530      3.700      0.000       0.922       2.999\n",
      "LeverZmax      -0.1162      0.076     -1.528      0.127      -0.265       0.033\n",
      "LeverZmin      -0.0234      0.091     -0.257      0.797      -0.202       0.155\n",
      "LeverAUC        0.0004      0.002      0.202      0.840      -0.004       0.004\n",
      "HLZmax          0.1045      0.253      0.413      0.679      -0.391       0.600\n",
      "HLZmin         -0.5161      0.323     -1.598      0.110      -1.149       0.117\n",
      "HLAUC           0.0019      0.005      0.378      0.705      -0.008       0.012\n",
      "===============================================================================\n"
     ]
    }
   ],
   "source": [
    "!pip install statsmodels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.534831\n",
      "         Iterations 7\n",
      "                          MNLogit Regression Results                          \n",
      "==============================================================================\n",
      "Dep. Variable:              NextLever   No. Observations:                  728\n",
      "Model:                        MNLogit   Df Residuals:                      714\n",
      "Method:                           MLE   Df Model:                           12\n",
      "Date:                Mon, 01 Jan 2024   Pseudo R-squ.:                 0.05240\n",
      "Time:                        21:47:01   Log-Likelihood:                -389.36\n",
      "converged:                       True   LL-Null:                       -410.89\n",
      "Covariance Type:            nonrobust   LLR p-value:                 2.208e-05\n",
      "===============================================================================\n",
      "NextLever=1       coef    std err          z      P>|z|      [0.025      0.975]\n",
      "-------------------------------------------------------------------------------\n",
      "const           1.3347      0.637      2.095      0.036       0.086       2.583\n",
      "LeverZmax      -0.4040      0.174     -2.321      0.020      -0.745      -0.063\n",
      "LeverZmin       0.0847      0.149      0.569      0.569      -0.207       0.376\n",
      "LeverAUC       -0.0010      0.004     -0.283      0.777      -0.008       0.006\n",
      "HLZmax          0.0930      0.314      0.296      0.767      -0.523       0.709\n",
      "HLZmin         -0.1734      0.396     -0.438      0.662      -0.949       0.603\n",
      "HLAUC           0.0010      0.006      0.166      0.868      -0.011       0.013\n",
      "-------------------------------------------------------------------------------\n",
      "NextLever=2       coef    std err          z      P>|z|      [0.025      0.975]\n",
      "-------------------------------------------------------------------------------\n",
      "const           1.9606      0.530      3.700      0.000       0.922       2.999\n",
      "LeverZmax      -0.1162      0.076     -1.528      0.127      -0.265       0.033\n",
      "LeverZmin      -0.0234      0.091     -0.257      0.797      -0.202       0.155\n",
      "LeverAUC        0.0004      0.002      0.202      0.840      -0.004       0.004\n",
      "HLZmax          0.1045      0.253      0.413      0.679      -0.391       0.600\n",
      "HLZmin         -0.5161      0.323     -1.598      0.110      -1.149       0.117\n",
      "HLAUC           0.0019      0.005      0.378      0.705      -0.008       0.012\n",
      "===============================================================================\n"
     ]
    }
   ],
   "source": [
    "import statsmodels.api as sm\n",
    "\n",
    "# Fit logistic regression using statsmodels for detailed statistics\n",
    "# Add a constant to the input features\n",
    "X_stat = sm.add_constant(X_train)\n",
    "model_stat = sm.MNLogit(y_train, X_stat)\n",
    "result_stat = model_stat.fit()\n",
    "\n",
    "# Print summary for detailed statistics\n",
    "print(result_stat.summary())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     feature  importance\n",
      "5      HLAUC    0.025000\n",
      "2   LeverAUC    0.019231\n",
      "3     HLZmax    0.000000\n",
      "4     HLZmin    0.000000\n",
      "1  LeverZmin   -0.002564\n",
      "0  LeverZmax   -0.012821\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\wonnp\\Documents\\GitHub\\ML-For-Beginners\\.virtualenv\\Lib\\site-packages\\sklearn\\base.py:458: UserWarning: X has feature names, but LogisticRegression was fitted without feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\wonnp\\Documents\\GitHub\\ML-For-Beginners\\.virtualenv\\Lib\\site-packages\\sklearn\\base.py:458: UserWarning: X has feature names, but LogisticRegression was fitted without feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\wonnp\\Documents\\GitHub\\ML-For-Beginners\\.virtualenv\\Lib\\site-packages\\sklearn\\base.py:458: UserWarning: X has feature names, but LogisticRegression was fitted without feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\wonnp\\Documents\\GitHub\\ML-For-Beginners\\.virtualenv\\Lib\\site-packages\\sklearn\\base.py:458: UserWarning: X has feature names, but LogisticRegression was fitted without feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\wonnp\\Documents\\GitHub\\ML-For-Beginners\\.virtualenv\\Lib\\site-packages\\sklearn\\base.py:458: UserWarning: X has feature names, but LogisticRegression was fitted without feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\wonnp\\Documents\\GitHub\\ML-For-Beginners\\.virtualenv\\Lib\\site-packages\\sklearn\\base.py:458: UserWarning: X has feature names, but LogisticRegression was fitted without feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\wonnp\\Documents\\GitHub\\ML-For-Beginners\\.virtualenv\\Lib\\site-packages\\sklearn\\base.py:458: UserWarning: X has feature names, but LogisticRegression was fitted without feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\wonnp\\Documents\\GitHub\\ML-For-Beginners\\.virtualenv\\Lib\\site-packages\\sklearn\\base.py:458: UserWarning: X has feature names, but LogisticRegression was fitted without feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\wonnp\\Documents\\GitHub\\ML-For-Beginners\\.virtualenv\\Lib\\site-packages\\sklearn\\base.py:458: UserWarning: X has feature names, but LogisticRegression was fitted without feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\wonnp\\Documents\\GitHub\\ML-For-Beginners\\.virtualenv\\Lib\\site-packages\\sklearn\\base.py:458: UserWarning: X has feature names, but LogisticRegression was fitted without feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\wonnp\\Documents\\GitHub\\ML-For-Beginners\\.virtualenv\\Lib\\site-packages\\sklearn\\base.py:458: UserWarning: X has feature names, but LogisticRegression was fitted without feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\wonnp\\Documents\\GitHub\\ML-For-Beginners\\.virtualenv\\Lib\\site-packages\\sklearn\\base.py:458: UserWarning: X has feature names, but LogisticRegression was fitted without feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\wonnp\\Documents\\GitHub\\ML-For-Beginners\\.virtualenv\\Lib\\site-packages\\sklearn\\base.py:458: UserWarning: X has feature names, but LogisticRegression was fitted without feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\wonnp\\Documents\\GitHub\\ML-For-Beginners\\.virtualenv\\Lib\\site-packages\\sklearn\\base.py:458: UserWarning: X has feature names, but LogisticRegression was fitted without feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\wonnp\\Documents\\GitHub\\ML-For-Beginners\\.virtualenv\\Lib\\site-packages\\sklearn\\base.py:458: UserWarning: X has feature names, but LogisticRegression was fitted without feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\wonnp\\Documents\\GitHub\\ML-For-Beginners\\.virtualenv\\Lib\\site-packages\\sklearn\\base.py:458: UserWarning: X has feature names, but LogisticRegression was fitted without feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\wonnp\\Documents\\GitHub\\ML-For-Beginners\\.virtualenv\\Lib\\site-packages\\sklearn\\base.py:458: UserWarning: X has feature names, but LogisticRegression was fitted without feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\wonnp\\Documents\\GitHub\\ML-For-Beginners\\.virtualenv\\Lib\\site-packages\\sklearn\\base.py:458: UserWarning: X has feature names, but LogisticRegression was fitted without feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\wonnp\\Documents\\GitHub\\ML-For-Beginners\\.virtualenv\\Lib\\site-packages\\sklearn\\base.py:458: UserWarning: X has feature names, but LogisticRegression was fitted without feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\wonnp\\Documents\\GitHub\\ML-For-Beginners\\.virtualenv\\Lib\\site-packages\\sklearn\\base.py:458: UserWarning: X has feature names, but LogisticRegression was fitted without feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\wonnp\\Documents\\GitHub\\ML-For-Beginners\\.virtualenv\\Lib\\site-packages\\sklearn\\base.py:458: UserWarning: X has feature names, but LogisticRegression was fitted without feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\wonnp\\Documents\\GitHub\\ML-For-Beginners\\.virtualenv\\Lib\\site-packages\\sklearn\\base.py:458: UserWarning: X has feature names, but LogisticRegression was fitted without feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\wonnp\\Documents\\GitHub\\ML-For-Beginners\\.virtualenv\\Lib\\site-packages\\sklearn\\base.py:458: UserWarning: X has feature names, but LogisticRegression was fitted without feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\wonnp\\Documents\\GitHub\\ML-For-Beginners\\.virtualenv\\Lib\\site-packages\\sklearn\\base.py:458: UserWarning: X has feature names, but LogisticRegression was fitted without feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\wonnp\\Documents\\GitHub\\ML-For-Beginners\\.virtualenv\\Lib\\site-packages\\sklearn\\base.py:458: UserWarning: X has feature names, but LogisticRegression was fitted without feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\wonnp\\Documents\\GitHub\\ML-For-Beginners\\.virtualenv\\Lib\\site-packages\\sklearn\\base.py:458: UserWarning: X has feature names, but LogisticRegression was fitted without feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\wonnp\\Documents\\GitHub\\ML-For-Beginners\\.virtualenv\\Lib\\site-packages\\sklearn\\base.py:458: UserWarning: X has feature names, but LogisticRegression was fitted without feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\wonnp\\Documents\\GitHub\\ML-For-Beginners\\.virtualenv\\Lib\\site-packages\\sklearn\\base.py:458: UserWarning: X has feature names, but LogisticRegression was fitted without feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\wonnp\\Documents\\GitHub\\ML-For-Beginners\\.virtualenv\\Lib\\site-packages\\sklearn\\base.py:458: UserWarning: X has feature names, but LogisticRegression was fitted without feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\wonnp\\Documents\\GitHub\\ML-For-Beginners\\.virtualenv\\Lib\\site-packages\\sklearn\\base.py:458: UserWarning: X has feature names, but LogisticRegression was fitted without feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\wonnp\\Documents\\GitHub\\ML-For-Beginners\\.virtualenv\\Lib\\site-packages\\sklearn\\base.py:458: UserWarning: X has feature names, but LogisticRegression was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "# Perform permutation importance\n",
    "perm_importance = permutation_importance(model, X_test, y_test)\n",
    "\n",
    "# Summarize in a DataFrame\n",
    "perm_importance_df = pd.DataFrame({'feature': feature_names, 'importance': perm_importance.importances_mean})\n",
    "perm_importance_df = perm_importance_df.sort_values(by='importance', ascending=False)\n",
    "\n",
    "print(perm_importance_df)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  },
  "metadata": {
   "interpreter": {
    "hash": "70b38d7a306a849643e446cd70466270a13445e5987dfa1344ef2b127438fa4d"
   }
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
